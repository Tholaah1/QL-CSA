{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e71c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e3f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML:\n",
    "    def __init__(self):\n",
    "        # Leer el archivo CSV\n",
    "        #self.data = np.loadtxt('knapsack_data.csv', delimiter=',', skiprows=1)\n",
    "        self.data = pd.read_csv('mitbih_test.csv', header= None)\n",
    "        cantidad_columnas = len(self.data.columns)\n",
    "        self.fitness_history = []\n",
    "        #print(\"Cantidad de columnas: \", cantidad_columnas)\n",
    "\n",
    "    def loadData(self, selected_features):\n",
    "        # Usa las caracteristicas dadas por la MH\n",
    "        ## Devuelve el conjunto de datos filtrado basado en las características seleccionadas.\n",
    "        all_features = list(self.data.columns)\n",
    "        print(\"Cantidad de columnas: \", len(all_features))\n",
    "        selected_column_names = [all_features[i] for i in range(len(selected_features)) if selected_features[i] == 1]\n",
    "        return self.data[selected_column_names].values, self.data.iloc[:, -1].values.astype(int)\n",
    "    \n",
    "    def obtenerCantidadColumnas(self):\n",
    "        # Devuelve la cantidad total de columnas en el conjunto de datos.\n",
    "        return len(self.data.columns)\n",
    "    \n",
    "# Función de fitness para la selección de características\n",
    "    def fitness(self, features, X, y):\n",
    "        # Seleccionamos las características de acuerdo a la solución (features)\n",
    "        ## Evalúa una solución basada en la precisión de un clasificador k-NN.\n",
    "        selected_features = [i for i, val in enumerate(features) if val == 1]\n",
    "        X_selected = X[:, selected_features]\n",
    "\n",
    "        # Dividimos en conjunto de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Evaluamos con KNN\n",
    "        knn_clf = KNeighborsClassifier()\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        knn_predictions = knn_clf.predict(X_test)\n",
    "        knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "\n",
    "        # Evaluamos con Decision Tree\n",
    "        dt_clf = DecisionTreeClassifier()\n",
    "        dt_clf.fit(X_train, y_train)\n",
    "        dt_predictions = dt_clf.predict(X_test)\n",
    "        dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "\n",
    "        # Evaluamos con Random Forest\n",
    "        rf_clf = RandomForestClassifier()\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        rf_predictions = rf_clf.predict(X_test)\n",
    "        rf_score = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "        # Evaluamos con SVM\n",
    "        svm_clf = SVC()\n",
    "        svm_clf.fit(X_train, y_train)\n",
    "        svm_predictions = svm_clf.predict(X_test)\n",
    "        svm_score = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "        # Usamos la precisión como medida de fitness\n",
    "        return (knn_accuracy, dt_accuracy, rf_score, svm_score)\n",
    "\n",
    "    def levy_flight(self, beta):\n",
    "        ## Genera un paso basado en una distribución de Lévy.\n",
    "        # Factor de escala para el paso\n",
    "        sigma = (math.gamma(1 + beta) * math.sin(math.pi * beta / 2) / \n",
    "                (math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n",
    "\n",
    "        u = np.random.normal(0, sigma, 1)\n",
    "        v = np.random.normal(0, 1, 1)\n",
    "        step = u / abs(v)**(1 / beta)\n",
    "    \n",
    "        return step\n",
    "\n",
    "    def generate_nest(self, num_features):\n",
    "        ## Genera un nido aleatorio (una solución binaria) basado en la cantidad de características.\n",
    "        return np.random.choice([0, 1], size=num_features)\n",
    "    \n",
    "    def init_q_table(self, num_nests, num_actions=2):\n",
    "        #Inicializamos Q-table con ceros. Las acciones son 0: No actualizar 1:Actualizar\n",
    "        return np.zeros((num_nests, num_actions))\n",
    "    \n",
    "    def choose_action(self, state, Q, epsilon=0.1):\n",
    "        # Selecciona una acción basada en una política epsilon-greedy.\n",
    "        if np.random.uniform(0,1) < epsilon:\n",
    "            return np.random.choice([0,1])\n",
    "        else:\n",
    "            return np.argmax(Q[state, :])\n",
    "         \n",
    "\n",
    "    def CSA(self, X, y, pa, max_iter, epsilon, beta, alpha, gamma, num_nests=None):\n",
    "        # Algoritmo de Cuckoo Search con aprendizaje por refuerzo.\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        if num_nests is None:\n",
    "            num_nests = len(self.data.columns)\n",
    "        \n",
    "        Q = self.init_q_table(num_nests)\n",
    "            \n",
    "        # Paso 1: Inicializar nidos\n",
    "        nests = [self.generate_nest(num_features) for _ in range(num_nests)]\n",
    "        fitness_values = [self.fitness(nest, X, y) for nest in nests]\n",
    "\n",
    "        # Inicializar el mejor nido y su puntuación.\n",
    "        best_nest = None\n",
    "        best_knn_score = -1\n",
    "        best_dt_score = -1\n",
    "        best_rf_score = -1\n",
    "        best_svm_score = -1\n",
    "\n",
    "        for iter in range(max_iter):\n",
    "            print(\"Iteracion: \", iter+1)\n",
    "            # Paso 2: Calcular el fitness de cada nido con cada uno de los clasificadores\n",
    "\n",
    "            knn_scores = [score[0] for score in fitness_values]\n",
    "            dt_scores = [score[1] for score in fitness_values]\n",
    "            rf_scores = [score[2] for score in fitness_values]\n",
    "            svm_scores = [score[3] for score in fitness_values]\n",
    "            \n",
    "            #scores = fitness_values.copy()\n",
    "            \n",
    "            # Agregar el fitness en el listado de los mejores fitness\n",
    "            self.fitness_history.append((max(knn_scores), max(dt_scores), max(rf_scores), max(svm_scores)))\n",
    "\n",
    "            # Paso 3: Encuentra el mejor nido o identificar el nido con la mejor puntuación.\n",
    "            current_best_nest = nests[np.argmax(knn_scores)]\n",
    "            current_best_knn_score = max(knn_scores)\n",
    "            current_best_dt_score = max(dt_scores)\n",
    "            current_best_rf_score = max(rf_scores)\n",
    "            current_best_svm_score = max(svm_scores)\n",
    "\n",
    "            if current_best_knn_score > best_knn_score:\n",
    "                best_knn_score = current_best_knn_score\n",
    "                best_nest = current_best_nest\n",
    "\n",
    "            if current_best_dt_score > best_dt_score:\n",
    "                best_dt_score = current_best_dt_score\n",
    "                best_nest = current_best_nest\n",
    "\n",
    "            if current_best_rf_score > best_rf_score:\n",
    "                best_rf_score = current_best_rf_score\n",
    "                best_nest = current_best_nest\n",
    "\n",
    "            if current_best_svm_score > best_svm_score:\n",
    "                best_svm_score = current_best_svm_score\n",
    "                best_nest = current_best_nest\n",
    "\n",
    "            # Paso 4: Actualizar nidos basado en Lévy flight y aprendizaje Q-learning.\n",
    "            for i in range(num_nests):\n",
    "                action = self.choose_action(i, Q)\n",
    "                \n",
    "                #Guardamos el score original de cada uno de los clasifiicadores\n",
    "                original_knn_score = knn_scores[i]\n",
    "                original_dt_score = dt_scores[i]\n",
    "                original_rf_score = rf_scores[i]\n",
    "                original_svm_score = svm_scores[i]\n",
    "                \n",
    "                # Si la acción es actualizar el nido.\n",
    "                if action == 1:\n",
    "                    if np.random.rand() > pa:\n",
    "                        # Aplicar Levy Flight para actualizar el nido.\n",
    "                        #nests[i] = nests[i] + self.levy_flight() * (best_nest - nests[i])\n",
    "                        #Utiliza el valor absoluto del vuelo de Lévy como una probabilidad p\n",
    "                        for j in range(num_features):\n",
    "                            if abs(self.levy_flight(beta)) > 0.5:\n",
    "                                nests[i][j] = 1 - nests[i][j]\n",
    "                        #nests[i] = nests[i] + (np.random.rand(num_features) > 0.5) * (best_nest - nests[i])\n",
    "\n",
    "                        # Reemplazar algunas características aleatoriamente para diversificación\n",
    "                        ## Diversificación: alterar una característica al azar.\n",
    "                        nests[i][np.random.choice(num_features)] = 1 - nests[i][np.random.choice(num_features)]\n",
    "                        fitness_values[i] = self.fitness(nests[i], X, y)\n",
    "                else:\n",
    "                    #No se hace nada, no se actualiza el nido\n",
    "                    pass\n",
    "\n",
    "                \n",
    "                # Actualizar la Q-table basado en la recompensa.\n",
    "                new_knn_score, new_dt_score, new_rf_score, new_svm_score = fitness_values[i]\n",
    "                #Recompensa: Variacion entre el fitness de la iteracion actual con el fitness de la iteracion pasada\n",
    "                reward_knn = new_knn_score - original_knn_score\n",
    "                reward_dt = new_dt_score - original_dt_score\n",
    "                reward_rf = new_rf_score - original_rf_score\n",
    "                reward_svm = new_svm_score - original_svm_score\n",
    "                reward_avg = (reward_knn + reward_dt + reward_rf + reward_svm) / 4\n",
    "                #Q[i, action] = Q[i, action] + 0.1 * (reward + 0.9 * np.max(Q[i, :]) - Q[i, action])\n",
    "                next_max_Q = np.max(Q[i, :])  # Estimación del valor Q máximo para el siguiente estado\n",
    "                Q[i, action] = Q[i, action] + alpha * (reward_avg + gamma * next_max_Q - Q[i, action])\n",
    "        \n",
    "        # Devuelve el mejor nido, su puntuación y la Q-table final.\n",
    "        return best_nest, (best_knn_score, best_dt_score, best_rf_score, best_svm_score), Q\n",
    "\n",
    "    def get_fitness_history(self):\n",
    "        return self.fitness_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c9fc5e-bc88-49e7-91a5-0bbd75aae7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de columnas:  188\n",
      "CONFIGURACION:  'pa': 0.5, 'max_iter': 100, 'epsilon': 0.16, 'beta': 1.4, 'alpha': 0.1, 'gamma': 0.6\n",
      "Iteracion:  1\n",
      "Iteracion:  2\n",
      "Iteracion:  3\n",
      "Iteracion:  4\n",
      "Iteracion:  5\n",
      "Iteracion:  6\n",
      "Iteracion:  7\n",
      "Iteracion:  8\n",
      "Iteracion:  9\n",
      "Iteracion:  10\n",
      "Iteracion:  11\n",
      "Iteracion:  12\n",
      "Iteracion:  13\n",
      "Iteracion:  14\n",
      "Iteracion:  15\n",
      "Iteracion:  16\n",
      "Iteracion:  17\n",
      "Iteracion:  18\n",
      "Iteracion:  19\n",
      "Iteracion:  20\n",
      "Iteracion:  21\n",
      "Iteracion:  22\n",
      "Iteracion:  23\n",
      "Iteracion:  24\n",
      "Iteracion:  25\n",
      "Iteracion:  26\n",
      "Iteracion:  27\n",
      "Iteracion:  28\n",
      "Iteracion:  29\n",
      "Iteracion:  30\n",
      "Iteracion:  31\n",
      "Iteracion:  32\n",
      "Iteracion:  33\n",
      "Iteracion:  34\n",
      "Iteracion:  35\n",
      "Iteracion:  36\n",
      "Iteracion:  37\n",
      "Iteracion:  38\n",
      "Iteracion:  39\n",
      "Iteracion:  40\n",
      "Iteracion:  41\n",
      "Iteracion:  42\n",
      "Iteracion:  43\n",
      "Iteracion:  44\n",
      "Iteracion:  45\n",
      "Iteracion:  46\n",
      "Iteracion:  47\n",
      "Iteracion:  48\n",
      "Iteracion:  49\n",
      "Iteracion:  50\n",
      "Iteracion:  51\n",
      "Iteracion:  52\n",
      "Iteracion:  53\n",
      "Iteracion:  54\n",
      "Iteracion:  55\n",
      "Iteracion:  56\n",
      "Iteracion:  57\n",
      "Iteracion:  58\n",
      "Iteracion:  59\n",
      "Iteracion:  60\n",
      "Iteracion:  61\n",
      "Iteracion:  62\n",
      "Iteracion:  63\n",
      "Iteracion:  64\n",
      "Iteracion:  65\n",
      "Iteracion:  66\n",
      "Iteracion:  67\n",
      "Iteracion:  68\n",
      "Iteracion:  69\n",
      "Iteracion:  70\n",
      "Iteracion:  71\n",
      "Iteracion:  72\n",
      "Iteracion:  73\n",
      "Iteracion:  74\n",
      "Iteracion:  75\n",
      "Iteracion:  76\n",
      "Iteracion:  77\n",
      "Iteracion:  78\n",
      "Iteracion:  79\n",
      "Iteracion:  80\n",
      "Iteracion:  81\n",
      "Iteracion:  82\n",
      "Iteracion:  83\n",
      "Iteracion:  84\n",
      "Iteracion:  85\n",
      "Iteracion:  86\n",
      "Iteracion:  87\n",
      "Iteracion:  88\n",
      "Iteracion:  89\n",
      "Iteracion:  90\n",
      "Iteracion:  91\n",
      "Iteracion:  92\n",
      "Iteracion:  93\n",
      "Iteracion:  94\n",
      "Iteracion:  95\n",
      "Iteracion:  96\n",
      "Iteracion:  97\n",
      "Iteracion:  98\n",
      "Iteracion:  99\n",
      "Iteracion:  100\n"
     ]
    }
   ],
   "source": [
    "ml_instance = ML()\n",
    "\n",
    "X, y = ml_instance.loadData([1 for _ in range(ml_instance.obtenerCantidadColumnas()-1)]) # Cargar todas las características inicialmente\n",
    "\n",
    "#Config: {'pa': 0.5, 'max_iter': 10, 'epsilon': 0.16, 'beta': 1.4, 'alpha': 0.1, 'gamma': 0.6}\n",
    "config = \"'pa': 0.5, 'max_iter': 100, 'epsilon': 0.16, 'beta': 1.4, 'alpha': 0.1, 'gamma': 0.6\"\n",
    "print(\"CONFIGURACION: \", config)\n",
    "best_features, best_accuracy, q_table = ml_instance.CSA(X, y, pa=0.5, max_iter=100, epsilon=0.16, beta=1.4, alpha=0.1, gamma=0.6)\n",
    "fitness_evolution = ml_instance.get_fitness_history()\n",
    "knn_accuracy = best_accuracy[0]\n",
    "dt_accuracy = best_accuracy[1]\n",
    "rf_accuracy = best_accuracy[2]\n",
    "svm_accuracy = best_accuracy[3]\n",
    "\n",
    "knn_history = [item[0] for item in fitness_evolution]\n",
    "dt_history = [item[1] for item in fitness_evolution]\n",
    "rf_history = [item[2] for item in fitness_evolution]\n",
    "svm_history = [item[3] for item in fitness_evolution]\n",
    "\n",
    "#Escribir los resultados en los archivos correspondientes\n",
    "with open(\"RESULTADOS-QLCSA.txt\", \"a\") as file:\n",
    "    file.write(\"Fecha y hora: \" + str(datetime.now()) + \"\\n\")\n",
    "    file.write(\"Parametros utilizados: \" + str(config) + \"\\n\")\n",
    "    file.write(\"Mejores características: \" + str(best_features) + \"\\n\")\n",
    "    file.write(\"Fitness (KNN): \" + str(knn_accuracy) + \"\\n\")\n",
    "    file.write(\"Fitness (Decision Tree): \" + str(dt_accuracy) + \"\\n\")\n",
    "    file.write(\"Fitness (Random Forest): \" + str(rf_accuracy) + \"\\n\")\n",
    "    file.write(\"Fitness (SVM): \" + str(svm_accuracy) + \"\\n\")\n",
    "    file.write(\"-------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "with open(\"QTABLE-QLCSA.txt\", \"a\") as file:\n",
    "    file.write(str(datetime.now()))\n",
    "    file.write(\"\\n\" + \" Q table: \" + str(q_table) + \"\\n\\n\")\n",
    "    file.write(\"-------------------------------------------------------------------------\\n\\n\")\n",
    "    \n",
    "with open(\"FITNESSEVOLUTION-QLCSA.txt\", \"a\") as file:\n",
    "    file.write(str(datetime.now()))\n",
    "    file.write(\"\\n\"+ \"KNN Fitness Evolution: \" + str(knn_history) + \"\\n\\n\")\n",
    "    file.write(\"\\n\"+ \"Decision Tree Fitness Evolution: \" + str(dt_history) + \"\\n\\n\")\n",
    "    file.write(\"\\n\"+ \"Random Forest Fitness Evolution: \" + str(rf_history) + \"\\n\\n\")\n",
    "    file.write(\"\\n\"+ \"SVM Fitness Evolution: \" + str(svm_history) + \"\\n\\n\")\n",
    "    file.write(\"-------------------------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5710541-b99c-4efd-85cd-b4c7b3a3f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
